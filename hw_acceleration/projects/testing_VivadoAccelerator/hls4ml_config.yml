AcceleratorConfig:
  Board: pynq-z2
  Driver: python
  Interface: axi_stream
  Precision:
    Input: float
    Output: float
Backend: VivadoAccelerator
ClockPeriod: 5
HLSConfig:
  LayerName:
    conv1:
      ConvImplementation: LineBuffer
      ParallelizationFactor: 1
      Precision:
        accum: fixed<16,6>
        bias: fixed<16,6>
        result: fixed<16,6>
        weight: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv1_bn:
      Precision:
        bias: fixed<16,6>
        result: fixed<16,6>
        scale: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv1_input:
      Precision:
        result: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv1_linear:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv1_relu:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_dw_1:
      ConvImplementation: LineBuffer
      ParallelizationFactor: 1
      Precision:
        accum: fixed<16,6>
        bias: fixed<16,6>
        result: fixed<16,6>
        weight: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_dw_1_bn:
      Precision:
        bias: fixed<16,6>
        result: fixed<16,6>
        scale: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_dw_1_linear:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_dw_1_relu:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_dw_2:
      ConvImplementation: LineBuffer
      ParallelizationFactor: 1
      Precision:
        accum: fixed<16,6>
        bias: fixed<16,6>
        result: fixed<16,6>
        weight: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_dw_2_bn:
      Precision:
        bias: fixed<16,6>
        result: fixed<16,6>
        scale: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_dw_2_linear:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_dw_2_relu:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_pw_1:
      ConvImplementation: LineBuffer
      ParallelizationFactor: 1
      Precision:
        accum: fixed<16,6>
        bias: fixed<16,6>
        result: fixed<16,6>
        weight: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_pw_1_bn:
      Precision:
        bias: fixed<16,6>
        result: fixed<16,6>
        scale: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_pw_1_linear:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_pw_1_relu:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_pw_2:
      ConvImplementation: LineBuffer
      ParallelizationFactor: 1
      Precision:
        accum: fixed<16,6>
        bias: fixed<16,6>
        result: fixed<16,6>
        weight: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_pw_2_bn:
      Precision:
        bias: fixed<16,6>
        result: fixed<16,6>
        scale: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    conv_pw_2_linear:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    conv_pw_2_relu:
      Precision:
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Strategy: Latency
      TableSize: 1024
      Trace: false
    global_average_pooling:
      Precision:
        accum: fixed<16,6>
        result: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    output:
      Precision:
        accum: fixed<16,6>
        bias: fixed<16,6>
        result: fixed<16,6>
        weight: fixed<16,6>
      ReuseFactor: 1
      Strategy: Latency
      Trace: false
    output_softmax:
      Implementation: stable
      Precision:
        exp_table: fixed<18,8,RND,SAT>
        inv_table: fixed<18,8,RND,SAT>
        result: fixed<16,6>
        table: fixed<18,8>
      ReuseFactor: 1
      Skip: false
      Strategy: Stable
      TableSize: 1024
      Trace: false
  Model:
    BramFactor: 1000000000
    Precision: ap_fixed<8,4>
    ReuseFactor: 1
    Strategy: Latency
    TraceOutput: false
IOType: io_stream
KerasModel: !keras_model '../projects/testing_VivadoAccelerator/keras_model.h5'
OutputDir: ../projects/testing_VivadoAccelerator
Part: xc7z020clg400-1
ProjectName: myproject
Stamp: F1EC16A1
Version: 1.0.0
XilinxPart: xc7z020clg400-1
